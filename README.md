# SLM_1920
Statistical Learning Methods - laboratories repository

### Organiztional information

Lecturers:

- _Lecture_: Bogumił Kamiński, [http://bogumilkaminski.pl](http://bogumilkaminski.pl/)
- _Laboratories_: Łukasz Kraiński, Michał Kot, Kinga Siuta, Agata Skorupka

Schedule information:

- _Lecture_:        Auditorium IV, Tuesdays, 8:00 – 10:35
- _Laboratories_:   A-113, Wednesdays, 17:10–18:50
  - group number:   102, meetings dates: 26-02-20;11-03-20;25-03-20;08-04-20;29-04-20;13-05-20;27-05-20;10-06-20;

### Lectures

| Date | Topic |
| --- | --- |
| 25-02-20 | Introduction to data science |
| 03-03-20 | Working with Git and Github |
| 10-03-20 | Introduction to Julia and Python programming for data science |
| 17-03-20 | Introduction to predictive modeling |
| 24-03-20 | Introduction to threading and distributed computing, K-nearest neighbors algorithm |
| 31-03-20 | Methods of evaluation of predictive model quality |
| 07-04-20 | Working with data frames in Julia and Python |
| 21-04-20 | Methods of predictive model selection |
| 28-04-20 | Regularization for predictive modeling |
| 05-05-20 | Introduction to approximation and local predictive models |
| 12-05-20 | Introduction to deep learning |
| 19-05-20 | Causality modeling: introduction |
| 26-05-20 | Causality modeling: algorithms |
| 02-06-20 | Storytelling with data |
| 09-06-20 | Data science in production environments + written examination |


### Laboratories

| Date | Topic |
| --- | --- |
| 26-02-20 | Refresher on R programming |
| 11-03-20 | Methods of evaluation of classifiers |
| 25-03-20 | Nonparametric regression models: smoothing spline, LOESS, GAM |
| 8-04-20 | Classic machine learning models: CART, random forest |
| 29-04-20 | Deep learning |
| 13-05-20 | To be specified |
| 27-05-20 | Modeling competition |
| 10-06-20 | Computer exam |


### Literature

- Stephen Boyd and Lieven Vandenberghe, Introduction to Applied Linear Algebra
(http://vmls-book.stanford.edu/)
- Gareth J., Witten D., Hastie T., Tibshirani R. (2013), An Introduction to Statistical Learning with Applications in R ([http://www-bcf.usc.edu/~gareth/ISL/](http://www-bcf.usc.edu/~gareth/ISL/))
-  Hastie T., Tibshirani R., Friedman J. (2013), The Elements of Statistical Learning
(http://www-stat.stanford.edu/~tibs/ElemStatLearn/)
- Optional: Kamiński B., Zawisza M. (2012), Receptury w R. Podręcznik dla ekonomisty, Oficyna
Wydawnicza SGH ([http://bogumilkaminski.pl/projekty/](http://bogumilkaminski.pl/projekty/))
- Optional: B. Kamiński, P. Szufel: Julia 1.0 Programming Cookbook, Packt Publishing, 2018
(https://www.packtpub.com/application-development/julia-10-programming-cookbook)


### Course evaluation criteria

You can obtain points for the following components:
- Written examination (50 points total):
  - Takes place at the last lecture
  - You can bring your own printed materials
- Laboratory examination (50 points total):
  - During last laboratory
  - In R
  - You can bring your own printed materials
- Possible extra points
  - Homeworks
  - Contests
  - These points will be "additional" - you cannot score more than 100 points in total.

The final grade is determined based on the sum of points scored at exams, contests etc. (maximum 100):

| From | To | Final grade |
| --- | --- | --- |
| 0 | 49 | 2.0 |
| 50 | 59 | 3.0 |
| 60 | 69 | 3.5 |
| 70 | 79 | 4.0 |
| 80 | 89 | 4.5 |
| 90 | 100 | 5.0 |
